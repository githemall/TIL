# 2025년 09월 09일 TIL 
## Trouble Shooting: Fine-tuning과 Feature Extraction의 학습시간 차이 거의 없음

### 겪은 문제 (Problem)
- 내가 만든 동물 분류 코드에서 Fine-tuning 방식과 Feature Extraction 방식의 성능이 분명 차이가 나야 했는데 정확도만 조금 높아지고 학습 시간 차이가 거의 나지 않았다.

### 원인 분석 (Cause)
- 코딩하면서 옵티마이저 설정을 잘못했을 수 있음
- 이미 사용한 스케줄러를 재사용 했을 수 있음
- 모델 계산이 너무 빨라서, 다른 곳에 병목이 있을 수 있음

### 해결 방법 (Solution)
- 첫번째와 두번째 가능한 원인은 문제 없었고, 세번째 원인을 검증해보기 위해 모델의 계산량을 늘려보았다.
  1. `batch_size`를 4에서 32로 늘렸더니 전체 시간은 줄었지만 두 모델의 시간차이는 여전히 미미했다.
  2. ResNet-18보다 훨씬 무거운 ResNet-50으로 모델을 교체했더니 시간차이가 더 벌어졌다.
결론: GPU의 성능이 너무 뛰어나 데이터 로딩 시간 대비 모델의 순수 계산 시간이 차지하는 비중이 매우 적음 

### 배운 점 (Takeaway)
- 코드의 알고리즘뿐만 아니라, 데이터 파이프라인과 하드웨어 성능이 전체 속도에 미치는 영향을 체감했다.

