# 2025년 8월 31일 TIL

## Fact: 동물 이미지 분류기, 전이학습의 전이 학습(Transfer Learning)의 Feature Extraction 전략

미리 학습된 모델(Pre-trained Model)을 활용하는 전이 학습에는 크게 두 가지 전략이 있다: **미세조정(Fine-tuning)**과 **특징 추출(Feature Extraction)**. 오늘 그중 특징 

추출 전략에 대해 깊이 이해했다.

### 알게 된 것 (What I learned)
 - PyTorch의 기존 예제를 참고하여 개, 고양이, 토끼, 햄스터의 이미지를 분류하는 간단한 동물 이미지 분류기를 만들었다.
 - `'train'`과 `'val'`을 구분하는 이유:
   + 학습(`train`)용 데이터: 모델이 다양한 상황을 학습하도록 이미지를 무작위로 자르고(`RandomResizedCrop`), 뒤집는(`RandomHorizontalFlip`) 등 데이터 증강(Augmentation)을 적용한다. 같은 사진을 매번 조금씩 다른 형태로 보여줘서, 모델이 일반화(generalization) 능력을 키우도록 돕는다.
   + 검증(`val`)용 데이터: 모델의 성능을 일관된 기준으로 평가해야 하므로, 무작위 변형 없이 이미지를 가운데에 맞춰 자르는(`CenterCrop`) 등 정적인 처리를 한다.
 - 특징 추출 전략은 미리 학습된 모델을 **'얼려둔 특징 추출기(Frozen Feature Extractor)'**와 **'새로 학습할 분류기(Trainable Classifier)'** 두 부분으로 나누어 사용하는 방식이다.
   + **특징 추출기 (몸통):** ResNet 같은 모델의 합성곱 층(Convolutional Layers) 부분. 수백만 장의 이미지(ImageNet)로 학습하며 얻은, 이미지의 보편적인 특징(선, 면, 질감, 복잡한 패턴 등)을 추출하는 능력을 가졌다. 이 부분은 매우 뛰어나므로, **가중치를 변경하지 않도록 얼려버린다(freeze).**
   + **분류기 (머리):** 모델의 가장 마지막에 있는 완전 연결 층(Fully-Connected Layer). 특징 추출기가 뽑아준 '특징 보고서'를 보고, 이것이 어떤 클래스에 속하는지 최종 판단을 내리는 부분이다. 우리는 이 부분만 **우리의 문제에 맞게 새로 교체한 뒤, 이 '새로운 머리'만 집중적으로 학습시킨다.**

마치 '카메라 부품 전문가(특징 추출기)'가 분석한 보고서를 보고 '신입사원(분류기)'이 최종 결정을 내리는 법만 배우는 것과 같다.

### 예시 코드 (Code Example)

PyTorch에서 이 전략은 아래 코드로 구현된다.

```python
# 1. 미리 학습된 모델을 불러온다. (전문가 채용)
model = models.resnet18(pretrained=True)

# 2. 모델의 모든 파라미터를 '학습되지 않도록' 동결시킨다. (전문가 지식 보존)
for param in model.parameters():
    param.requires_grad = False

# 3. 마지막 분류기(머리)만 우리의 클래스 개수에 맞게 새로 교체한다.
# 새로 생성된 레이어는 기본적으로 param.requires_grad = True 상태이다. (신입사원 채용)
num_classes = 3 # 예시: 라면 3종 분류
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, num_classes)

# 4. 옵티마이저에게 "오직 새로운 분류기의 파라미터만 학습시켜라"고 알려준다.
# model.parameters()가 아닌 model.fc.parameters()를 전달하는 것이 핵심이다.
optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)
```


## Trouble Shooting: PyTorch PNG 이미지 예측 시 채널 불일치 `RuntimeError`

### 겪은 문제 (Problem)

학습된 모델로 단일 이미지를 예측하는 함수(`visualize_model_predictions`)를 테스트했다. `.jpg` 확장자 이미지를 넣었을 때는 예측이 잘 되었지만, `.png` 확장자 이미지를 넣자 아래와 같은 `RuntimeError`가 발생했다.

```bash
RuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0
```

### 원인 분석 (Cause)
에러 메시지는 텐서 크기 4와 3이 맞지 않는다고 알려주고 있었다. 이미지 처리에서 이 숫자는 보통 채널(Channel) 수를 의미한다.

JPG vs PNG: JPG 이미지는 대부분 **3채널 (RGB)**인 반면, PNG 이미지는 투명도(Alpha)를 포함한 **4채널 (RGBA)**인 경우가 많다.

transforms.Normalize: 내 데이터 전처리 파이프라인에는 3채널(RGB) 기준으로 정의된 정규화 단계가 포함되어 있다. (mean과 std가 각각 3개의 값을 가짐)

결론: 4채널 RGBA 이미지가 Image.open()으로 그대로 로드된 후, 3채널을 가정하는 Normalize 단계를 통과하려고 하니 채널 수가 맞지 않아 오류가 발생한 것이었다.

※ 추가 궁금증: 학습 시에는 PNG 파일이 있어도 문제가 없었던 이유는, datasets.ImageFolder가 내부적으로 이미지를 불러올 때 3채널 RGB 형식으로 자동 변환해주기 때문이었다. 수동으로 이미지를 하나씩 열 때는 이 과정이 생략된다.

### 해결 방법 (Solution)
Image.open()으로 이미지를 연 직후, .convert('RGB') 메소드를 호출하여 이미지를 명시적으로 3채널 RGB 형식으로 변환해준다.
```python
from PIL import Image

# ... 함수 내부 ...

img = Image.open(img_path)
# [해결 코드] RGBA 이미지가 들어와도 RGB로 변환하여 채널 수를 3으로 통일시킨다.
img = img.convert('RGB') 

# 이후 transform 과정은 문제없이 진행된다.
img = data_transforms['val'](img) 
# ...
```
### 참고 자료 (Reference)
- [https://tutorials.pytorch.kr/beginner/transfer_learning_tutorial.html](https://tutorials.pytorch.kr/beginner/transfer_learning_tutorial.html)

### 배운 점 (Takeaway)
딥러닝 모델에 이미지를 입력하기 전에는 데이터의 채널 수를 통일하는 것이 매우 중요하다는 것을 깨달았다.

JPG는 RGB(3채널), PNG는 RGBA(4채널)일 수 있다는 차이점을 명확히 인지하게 되었다.

PIL 라이브러리의 .convert('RGB')는 이미지의 채널 수를 강제로 RGB로 맞춰주는 편리하고 강력한 도구다.

ImageFolder와 같이 대량의 데이터를 다루는 헬퍼 함수들은 내부적으로 많은 예외 처리를 자동으로 해주지만, 단일 데이터를 직접 다룰 때는 개발자가 이런 세세한 부분을 직접 처리해야 한다는 것을 배웠다.



